{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facebook_scraper in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.2.59)\n",
      "Requirement already satisfied: dateparser<2.0.0,>=1.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from facebook_scraper) (1.1.8)\n",
      "Requirement already satisfied: demjson3<4.0.0,>=3.0.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from facebook_scraper) (3.0.6)\n",
      "Requirement already satisfied: requests-html<0.11.0,>=0.10.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from facebook_scraper) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (2.8.2)\n",
      "Requirement already satisfied: pytz in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (2023.3.post1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (2023.10.3)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.31.0)\n",
      "Requirement already satisfied: pyquery in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.0.0)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.3.0)\n",
      "Requirement already satisfied: parse in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.19.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (0.0.1)\n",
      "Requirement already satisfied: w3lib in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.1.2)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.0.2)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2021 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2023.7.22)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (6.8.0)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (8.2.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.64.1)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.26.17)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (10.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bs4->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.12.2)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyquery->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.9.3)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyquery->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil->dateparser<2.0.0,>=1.0.0->facebook_scraper) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.10)\n",
      "Requirement already satisfied: tzdata in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tzlocal->dateparser<2.0.0,>=1.0.0->facebook_scraper) (2023.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (3.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->bs4->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.1->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.1->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.1->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#installing librairies\n",
    "%pip install facebook_scraper\n",
    "%pip install pandas \n",
    "%pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\facebook_scraper\\facebook_scraper.py:855: UserWarning: Facebook language detected as fr_FR - for best results, set to en_US\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc335bdc2f649a9907cc069fd692ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Name: Amazon.com\n",
      "Comment: The best\n",
      "Positive\n",
      "Comment: They keep on losing my packages and they never get delivered\n",
      "Neutral\n",
      "Comment: This post is Brian Tirbovich post : I always like going on line shopping with Amazon and I never had trouble getting my money back when I returned the items but now they have to get into my e-mail and our e- mail is full and we cannot get into it and they will not allow me to talk to a supervisor which I think is unfair .\n",
      "Negative\n",
      "Comment: Información\n",
      "Neutral\n",
      "No more posts to scrape.\n",
      "Page Name: Amazon.com\n",
      "No more posts to scrape.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579a5b88c0d84d2c99d6e475e423cab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Name: Amazon.com\n",
      "Comment: Good luck 🍀\n",
      "Positive\n",
      "Comment: Very nice beautiful\n",
      "Positive\n",
      "Comment: My step brother worked for yall for 5 years and he said they would investigate that kind of stuff too. I sent it to the abuse thing tellin them how im upset at this\n",
      "Positive\n",
      "Comment: Kerry Carr\n",
      "Neutral\n",
      "Comment: Kerry Carr\n",
      "Neutral\n",
      "Comment: Wow!! I cant believe Amazon lets this go on in its wharehouses!! I worked at LEX 2 years ago and they would investigate this kind of stuff\n",
      "Positive\n",
      "No more posts to scrape.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14e9d50ef4b4689b437932bd7cccbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Name: Amazon.com\n",
      "Comment: Good luck 🍀\n",
      "Positive\n",
      "Comment: Very nice beautiful\n",
      "Positive\n",
      "Comment: My step brother worked for yall for 5 years and he said they would investigate that kind of stuff too. I sent it to the abuse thing tellin them how im upset at this\n",
      "Positive\n",
      "Comment: Kerry Carr\n",
      "Neutral\n",
      "Comment: Kerry Carr\n",
      "Neutral\n",
      "Comment: Wow!! I cant believe Amazon lets this go on in its wharehouses!! I worked at LEX 2 years ago and they would investigate this kind of stuff\n",
      "Positive\n",
      "No more posts to scrape.\n",
      "Page Name: Amazon.com\n",
      "No more posts to scrape.\n",
      "Page Name: Amazon.com\n",
      "No more posts to scrape.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41a1e49c4ae45a8ad80fb182a60aeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Name: Amazon.com\n",
      "Comment: Handsome 🍀\n",
      "Positive\n",
      "Comment: Those are certainly different!\n",
      "Neutral\n",
      "Comment: Reminds me of the early 60s .The mailman used three wheeler.( Cushman)\n",
      "Positive\n",
      "Comment: How on God’s glorious Earth is that a bike?\n",
      "Neutral\n",
      "Comment: Hiring?\n",
      "Neutral\n",
      "Comment: Edgar Verastegui let's go 😄\n",
      "Neutral\n",
      "No more posts to scrape.\n",
      "Page Name: Amazon.com\n",
      "No more posts to scrape.\n",
      "Page Name: Amazon.com\n",
      "No more posts to scrape.\n",
      "Page Name: Amazon.com\n",
      "No more posts to scrape.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d8922eff464ae7b377f5906a159a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Name: Amazon.com\n",
      "Comment: Boy oh Boy, do you need these in Los Angeles!!!\n",
      "Neutral\n",
      "No more posts to scrape.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d50a911c48042769b75d38434cf1d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Name: Amazon.com\n",
      "Comment: Swag swagggg!\n",
      "Neutral\n",
      "Comment: Soft berry's\n",
      "Positive\n",
      "Comment: L\n",
      "Neutral\n",
      "Comment: Subject: Exclusive Truck T-shirt Now Available on Amazon!\n",
      "\n",
      "Hey there,\n",
      "\n",
      "I hope you're doing well! I'm thrilled to share some exciting news with you—I've just listed my Truck-themed T-shirt on Amazon! Now, you can easily grab one for yourself or as a gift for any truck enthusiast you know.\n",
      "\n",
      "**Why You'll Love Our Truck T-shirt:**\n",
      "- Premium quality fabric for ultimate comfort.\n",
      "- Unique and eye-catching truck-themed design.\n",
      "- Available in a variety of sizes for men and women.\n",
      "\n",
      "**Price and Availability:**\n",
      "You can get your hands on these awesome T-shirts for just 13,99 each, and they're available with convenient shipping options. Visit the Amazon product page using the link below to place your order:\n",
      "\n",
      "https://\n",
      "www.amazon.com/\n",
      "dp/\n",
      "B0CJPBTVF2?custo\n",
      "mId=B0752XJYNL&\n",
      "customizationTo\n",
      "ken=MC_Assembly\n",
      "_1%23B0752XJYNL\n",
      "&th=1\n",
      "\n",
      "**Spread the Word:**\n",
      "If you love the design as much as I do, please consider leaving a review on Amazon to help others discover this amazing T-shirt. And if you have friends or family who might be interested, please share the link with them too!\n",
      "\n",
      "Thank you for your support, and I can't wait to see you rocking the Truck T-shirt. Happy shopping!\n",
      "\n",
      "Best regards,\n",
      "Anasse\n",
      "Positive\n",
      "No more posts to scrape.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2a9c63a7234b36a80323ba7e4624a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Name: Amazon.com\n",
      "Comment: W\n",
      "Neutral\n",
      "No more posts to scrape.\n",
      "Data saved to scraped_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import facebook_scraper as fs\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# URLs of the Facebook posts we want to start with\n",
    "post_urls = [\n",
    "    'https://www.facebook.com/photo/?fbid=885132786398578&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=885132783065245&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=885132779731912&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=885132779731912&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=884463179798872&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=884463169798873&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=882984716613385&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=882984679946722&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=882984626613394&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=882984619946728&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=882984613280062&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=878774437034413&set=pb.100047055939780.-2207520000',\n",
    "    'https://www.facebook.com/photo/?fbid=878774407034416&set=pb.100047055939780.-2207520000'\n",
    "]\n",
    "\n",
    "# Number of comments to download for each post\n",
    "\n",
    "MAX_COMMENTS = 100\n",
    "\n",
    "# Number of additional posts to scrape\n",
    "num_posts_to_scrape = 100  \n",
    "\n",
    "# Initializing a list to store the scraped posts\n",
    "posts_data = []\n",
    "\n",
    "data = []\n",
    "\n",
    "for post_url in post_urls:\n",
    "    # Getting the post (this gives a generator)\n",
    "    gen = fs.get_posts(\n",
    "        post_urls=[post_url],\n",
    "        options={\"comments\": MAX_COMMENTS, \"progress\": True}\n",
    "    )\n",
    "\n",
    "    # Getting the page details\n",
    "    page_info = fs.get_page_info(post_url)\n",
    "    # Iterating over the posts to get started\n",
    "    for i in range(num_posts_to_scrape):\n",
    "        try:\n",
    "            post = next(gen)\n",
    "        except StopIteration:\n",
    "            print(f\"No more posts to scrape.\")\n",
    "            break\n",
    "\n",
    "        # Extracting the post information\n",
    "        page_name = post['username']\n",
    "\n",
    "        # Printing the page information\n",
    "        print(f\"Page Name: {page_name}\")\n",
    "     \n",
    "\n",
    "        # Extracting the comments part\n",
    "        comments = post['comments_full']\n",
    "\n",
    "        # Processing comments \n",
    "        for comment in comments:\n",
    "            comment_text = comment['comment_text']  \n",
    "            comment_blob = TextBlob(comment_text)\n",
    "            comment_sentiment = comment_blob.sentiment.polarity\n",
    "\n",
    "            # Defining a function to interpret sentiment polarity\n",
    "            def interpret_sentiment(polarity):\n",
    "                if polarity > 0:\n",
    "                    return \"Positive\"\n",
    "                elif polarity < 0:\n",
    "                    return \"Negative\"\n",
    "                else:\n",
    "                    return \"Neutral\"\n",
    "\n",
    "            # Analyzing and printing the sentiment of the comment\n",
    "            print(\"Comment:\", comment_text)\n",
    "            Sentiment= interpret_sentiment(comment_sentiment)\n",
    "            print(Sentiment)\n",
    "        \n",
    "            posts_data.append(post)\n",
    "            post_url = post_url\n",
    "         \n",
    "        post_id = post['post_id']\n",
    "        likes = post['likes']\n",
    "        reaction_count = post['reaction_count']\n",
    "        reactions = post['reactions']\n",
    "        shared_time = post['shared_time']\n",
    "        caption = post['text']\n",
    "        date = post['time'].date()\n",
    "        time = post['time'].time()\n",
    "\n",
    "        # Extracting and processing comments\n",
    "        comments = post['comments_full']\n",
    "        for comment in comments:\n",
    "            comment_text = comment['comment_text']\n",
    "            comment_blob = TextBlob(comment_text)\n",
    "            comment_sentiment = comment_blob.sentiment.polarity\n",
    "            Sentiment = interpret_sentiment(comment_sentiment)\n",
    "\n",
    "            # Appending each comment to the data list\n",
    "            row = [page_name, post_id, reaction_count, reactions, shared_time, caption, date, time, post_url, likes, comment_text, Sentiment]\n",
    "            data.append(row)\n",
    "\n",
    "# Defining the column names\n",
    "columns = [\n",
    "    'page_name', 'post_id', 'reaction_count', 'reactions', 'shared_time', 'caption', 'date', 'time', 'post_url', 'likes', 'comment_text', 'comment_sentiment'\n",
    "]\n",
    "\n",
    "# Creating a DataFrame from the scraped data\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Saving the DataFrame to an Excel file\n",
    "excel_file = 'scraped_data.xlsx'\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "# Printing a message to confirm that the data has been saved\n",
    "print(f\"Data saved to {excel_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
